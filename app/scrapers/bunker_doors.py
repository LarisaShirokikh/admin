"""
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∫—Ä–∞–ø–µ—Ä –¥–ª—è —Å–∞–π—Ç–∞ Bunker Doors
"""
from typing import List, Dict, Any, Optional
import logging
import json
import re
from bs4 import BeautifulSoup
from sqlalchemy import func, or_, select
from sqlalchemy.ext.asyncio import AsyncSession

from app.models.product import Product
from app.models.catalog import Catalog
from app.schemas.product import ProductCreate
from app.schemas.product_image import ProductImageCreate
from app.utils.text_utils import generate_slug, clean_text
from app.crud.product import create_or_update_product
from app.scrapers.base_scraper import BaseScraper

logger = logging.getLogger("bunker_doors_scraper")

class BunkerDoorsScraper(BaseScraper):
    def __init__(self):
        super().__init__(
            brand_name="–ë—É–Ω–∫–µ—Ä",
            brand_slug="bunker",
            base_url="https://bunkerdoors.ru",
            logger_name="bunker_doors_scraper"
        )
    
    def extract_product_links_from_page(self, soup: BeautifulSoup, base_url: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞
        """
        product_links = []
        
        # –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã –≤ —Å–ø–∏—Å–∫–µ
        items = soup.select("li.products-list-01-item")
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
        
        for i, item in enumerate(items):
            try:
                # –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —Ç–æ–≤–∞—Ä —Ä–∞–∑–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏
                link_element = None
                
                # –°–ø–æ—Å–æ–± 1: –ò—â–µ–º —Å—Å—ã–ª–∫—É –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Ç–æ–≤–∞—Ä–∞
                img_link = item.select_one(".products-list-01-item__img a")
                if img_link and img_link.get('href'):
                    link_element = img_link
                    self.logger.info(f"–¢–æ–≤–∞—Ä {i+1}: –Ω–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
                
                # –°–ø–æ—Å–æ–± 2: –ò—â–µ–º —Å—Å—ã–ª–∫—É –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
                if not link_element:
                    title_link = item.select_one(".products-list-01-item__header a")
                    if title_link and title_link.get('href'):
                        link_element = title_link
                        self.logger.info(f"–¢–æ–≤–∞—Ä {i+1}: –Ω–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ")
                
                # –°–ø–æ—Å–æ–± 3: –ò—â–µ–º –ª—é–±—É—é —Å—Å—ã–ª–∫—É —Å href —Å–æ–¥–µ—Ä–∂–∞—â–∏–º —Ç–æ–≤–∞—Ä–Ω—ã–π –∫–æ–¥
                if not link_element:
                    all_links = item.select("a[href]")
                    for link in all_links:
                        href = link.get('href', '')
                        if any(pattern in href for pattern in ['/bn-', '/fl-', '/prod/']):
                            link_element = link
                            self.logger.info(f"–¢–æ–≤–∞—Ä {i+1}: –Ω–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É: {href}")
                            break
                
                # –°–ø–æ—Å–æ–± 4: –ü–µ—Ä–≤–∞—è —Å—Å—ã–ª–∫–∞ –≤ —ç–ª–µ–º–µ–Ω—Ç–µ (–µ—Å–ª–∏ –¥—Ä—É–≥–∏—Ö —Å–ø–æ—Å–æ–±–æ–≤ –Ω–µ—Ç)
                if not link_element:
                    first_link = item.select_one("a[href]")
                    if first_link:
                        link_element = first_link
                        self.logger.info(f"–¢–æ–≤–∞—Ä {i+1}: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–≤–∞—è —Å—Å—ã–ª–∫–∞")
                
                if link_element:
                    href = link_element.get('href')
                    if href:
                        full_url = self.normalize_url(href)
                        product_links.append(full_url)
                        self.logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ —Ç–æ–≤–∞—Ä–∞ {i+1}: {full_url}")
                    else:
                        self.logger.warning(f"–¢–æ–≤–∞—Ä {i+1}: –ø—É—Å—Ç–æ–π href")
                else:
                    self.logger.warning(f"–¢–æ–≤–∞—Ä {i+1}: –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞")
                    
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Å—Å—ã–ª–∫–∏ —Ç–æ–≤–∞—Ä–∞ {i+1}: {e}")
        
        self.logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(product_links)} —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã")
        return product_links
    
    def get_pagination_urls(self, soup: BeautifulSoup, current_url: str) -> List[str]:
        """
        –ù–û–í–û–ï: –ò–∑–≤–ª–µ–∫–∞–µ—Ç URL —Å—Ç—Ä–∞–Ω–∏—Ü –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
        """
        pagination_urls = []
        
        # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
        pagination_selectors = [
            ".pagination a",
            ".pages a", 
            ".page-numbers a",
            "a[href*='page']"
        ]
        
        for selector in pagination_selectors:
            links = soup.select(selector)
            if links:
                for link in links:
                    href = link.get('href')
                    if href and href != current_url:
                        full_url = self.normalize_url(href)
                        if full_url not in pagination_urls:
                            pagination_urls.append(full_url)
                break
        
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(pagination_urls)} —Å—Ç—Ä–∞–Ω–∏—Ü –ø–∞–≥–∏–Ω–∞—Ü–∏–∏")
        return pagination_urls
    
    def parse_product_page(self, product_url: str) -> Optional[Dict[str, Any]]:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü–∞—Ä—Å–∏—Ç –æ—Ç–¥–µ–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏
        """
        self.logger.debug(f"–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–æ–≤–∞—Ä–∞: {product_url}")
        
        html_content = self.get_html_content(product_url)
        if not html_content:
            self.logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã {product_url}")
            return None
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        try:
            product_data = {
                'url': product_url,
                'name': '',
                'price': 0,
                'old_price': 0,
                'description': '',
                'characteristics': {},
                'images': [],
                'in_stock': True,
                'article': '',
                'meta_title': '',
                'meta_description': ''
            }
            
            # 1. –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ (–ò–°–ü–†–ê–í–õ–ï–ù–û)
            title_selectors = [
                "h1.product-01__title",
                ".product-title h1",
                "h1"
            ]
            
            for selector in title_selectors:
                title_elem = soup.select_one(selector)
                if title_elem:
                    product_data['name'] = clean_text(title_elem.get_text())
                    self.logger.debug(f"–ù–∞–π–¥–µ–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–µ: {product_data['name']}")
                    break
            
            # 2. –¶–µ–Ω–∞ —Ç–æ–≤–∞—Ä–∞ (–ò–°–ü–†–ê–í–õ–ï–ù–û)
            price_elem = soup.select_one(".product-01__price")
            if price_elem:
                price_text = price_elem.get_text(strip=True)
                product_data['price'] = self.extract_price_from_text(price_text)
                if product_data['price'] > 0:
                    self.logger.debug(f"–ù–∞–π–¥–µ–Ω–∞ —Ü–µ–Ω–∞: {product_data['price']}")
            
            # 3. –°—Ç–∞—Ä–∞—è —Ü–µ–Ω–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å —Å–∫–∏–¥–∫–∞)
            old_price_elem = soup.select_one(".product-01__old-price")
            if old_price_elem:
                old_price_text = old_price_elem.get_text(strip=True)
                product_data['old_price'] = self.extract_price_from_text(old_price_text)
                if product_data['old_price'] > 0:
                    self.logger.debug(f"–ù–∞–π–¥–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è —Ü–µ–Ω–∞: {product_data['old_price']}")
            
            # 4. –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑ —Å–µ–∫—Ü–∏–∏ product-description
            description_parts = []
            
            # –û—Å–Ω–æ–≤–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            desc_elem = soup.select_one(".product-description")
            if desc_elem:
                description_parts.append(clean_text(desc_elem.get_text()))
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –¥—Ä—É–≥–∏—Ö —Å–µ–∫—Ü–∏–π
            additional_desc = soup.select_one(".product-01__description")
            if additional_desc:
                description_parts.append(clean_text(additional_desc.get_text()))
            
            product_data['description'] = " ".join(description_parts).strip()
            
            # 5. –ò–°–ü–†–ê–í–õ–ï–ù–û: –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            characteristics = {}
            
            # –ü–∞—Ä—Å–∏–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ —Å–ø–∏—Å–∫–∞
            param_items = soup.select(".product-01__parameters-item")
            for item in param_items:
                term_elem = item.select_one(".product-01__parameters-item-term")
                desc_elem = item.select_one(".product-01__parameters-item-desc")
                
                if term_elem and desc_elem:
                    key = clean_text(term_elem.get_text())
                    value = clean_text(desc_elem.get_text())
                    if key and value:
                        characteristics[key] = value
            
            product_data['characteristics'] = characteristics
            self.logger.debug(f"–ù–∞–π–¥–µ–Ω–æ {len(characteristics)} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫")
            
            # 6. –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            images = []
            
            # –ì–ª–∞–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            main_image = soup.select_one(".product-gallery-04__stage-item-img-container")
            if main_image:
                img_url = main_image.get('href')
                if img_url:
                    full_img_url = self.normalize_url(img_url)
                    if self.is_valid_image_url(full_img_url):
                        images.append(full_img_url)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –≥–∞–ª–µ—Ä–µ–∏
            gallery_images = soup.select(".product-gallery-04__list-item img")
            for img in gallery_images:
                img_src = img.get('data-bc-lazy-path') or img.get('src')
                if img_src:
                    full_img_url = self.normalize_url(img_src)
                    if self.is_valid_image_url(full_img_url) and full_img_url not in images:
                        images.append(full_img_url)
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∏—â–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏
            if not images:
                alt_images = soup.select(".product-01 img, .product-gallery img")
                for img in alt_images:
                    img_src = img.get('src') or img.get('data-src')
                    if img_src:
                        full_img_url = self.normalize_url(img_src)
                        if self.is_valid_image_url(full_img_url) and full_img_url not in images:
                            images.append(full_img_url)
            
            product_data['images'] = images
            self.logger.debug(f"–ù–∞–π–¥–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            
            # 7. –ê—Ä—Ç–∏–∫—É–ª —Ç–æ–≤–∞—Ä–∞
            article_elem = soup.select_one(".product-01__article")
            if article_elem:
                article_text = clean_text(article_elem.get_text())
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –∞—Ä—Ç–∏–∫—É–ª –∏–∑ —Ç–µ–∫—Å—Ç–∞
                article_match = re.search(r'([A-Za-z0-9\-]+)', article_text)
                if article_match:
                    product_data['article'] = article_match.group(1)
            
            # 8. –ù–∞–ª–∏—á–∏–µ —Ç–æ–≤–∞—Ä–∞
            in_stock = True
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ "–Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏"
            page_text = soup.get_text().lower()
            if any(phrase in page_text for phrase in ['–Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏', '–ø–æ–¥ –∑–∞–∫–∞–∑', '–Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω']):
                in_stock = False
            
            product_data['in_stock'] = in_stock
            
            # 9. –ú–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            title_tag = soup.select_one("title")
            if title_tag:
                product_data['meta_title'] = clean_text(title_tag.get_text())
            
            meta_desc = soup.select_one("meta[name='description']")
            if meta_desc:
                product_data['meta_description'] = meta_desc.get('content', '')
            
            self.logger.debug(f"–£—Å–ø–µ—à–Ω–æ —Å–ø–∞—Ä—Å–µ–Ω —Ç–æ–≤–∞—Ä: {product_data['name']}")
            return product_data
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ç–æ–≤–∞—Ä–∞ {product_url}: {e}", exc_info=True)
            return None
    
    async def parse_bunker_doors_products(self, catalog_url: str, db: AsyncSession) -> List[ProductCreate]:
        """
        –ü–∞—Ä—Å–∏—Ç —Ç–æ–≤–∞—Ä—ã —Å —Å–∞–π—Ç–∞ Bunker Doors –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞
        """
        self.logger.info(f"–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è –∫–∞—Ç–∞–ª–æ–≥–∞ {catalog_url}")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL
        catalog_url = self.normalize_url(catalog_url)
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥ –∏–∑ URL
        catalog_slug = catalog_url.rstrip('/').split('/')[-1]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è –∫–∞—Ç–∞–ª–æ–≥–∞
        catalog_name_part = catalog_slug.replace('-', ' ').title()
        catalog_name = f"–í—Ö–æ–¥–Ω—ã–µ –¥–≤–µ—Ä–∏ –ë—É–Ω–∫–µ—Ä {catalog_name_part}"
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥
        brand_id = await self.ensure_brand_exists(db)
        await db.commit()
        catalog = await self.get_or_create_catalog(db, catalog_name, catalog_slug, brand_id)
        await db.commit()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–∞—Ç–∞–ª–æ–≥ —Å–æ–∑–¥–∞–Ω –∏ –∏–º–µ–µ—Ç ID
        if not catalog or catalog.id is None:
            self.logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–∞—Ç–∞–ª–æ–≥ –¥–ª—è {catalog_url}")
            return []
            
        catalog_id = catalog.id
        self.logger.info(f"–ü–æ–ª—É—á–µ–Ω –∫–∞—Ç–∞–ª–æ–≥ —Å ID: {catalog_id}")

        from app.models.catalog import Catalog
        result = await db.execute(select(Catalog).where(Catalog.id == catalog_id))
        catalog_check = result.scalar_one_or_none()
        
        if not catalog_check:
            self.logger.error(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ö–∞—Ç–∞–ª–æ–≥ —Å ID {catalog_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è!")
            return []
        
        self.logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞ –ø—Ä–æ–π–¥–µ–Ω–∞: '{catalog_check.name}' —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –ë–î")
    
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã (–≤–∫–ª—é—á–∞—è –ø–∞–≥–∏–Ω–∞—Ü–∏—é)
        all_product_links = []
        processed_urls = set()
        urls_to_process = [catalog_url]
        
        while urls_to_process:
            current_url = urls_to_process.pop(0)
            
            if current_url in processed_urls:
                continue
                
            processed_urls.add(current_url)
            
            self.logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {current_url}")
            
            # –ü–æ–ª—É—á–∞–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞
            html_content = self.get_html_content(current_url)
            if not html_content:
                self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_url}")
                continue
                
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã
            product_links = self.extract_product_links_from_page(soup, self.base_url)
            all_product_links.extend(product_links)
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            pagination_urls = self.get_pagination_urls(soup, current_url)
            for page_url in pagination_urls:
                if page_url not in processed_urls:
                    urls_to_process.append(page_url)
        
        if not all_product_links:
            self.logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã –≤ –∫–∞—Ç–∞–ª–æ–≥–µ {catalog_url}")
            return []
        
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(all_product_links)} —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã")
        
        products = []
        first_product_image = None  # –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞
        
        # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—ã–π —Ç–æ–≤–∞—Ä –æ—Ç–¥–µ–ª—å–Ω–æ
        for i, product_url in enumerate(all_product_links):
            try:
                self.logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–≤–∞—Ä {i+1}/{len(all_product_links)}: {product_url}")
                
                # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞
                product_data = self.parse_product_page(product_url)
                
                if not product_data:
                    self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–ø–∞—Ä—Å–∏—Ç—å —Ç–æ–≤–∞—Ä {product_url}")
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                if not product_data['name']:
                    self.logger.warning(f"–£ —Ç–æ–≤–∞—Ä–∞ {product_url} –Ω–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    continue
                
                if product_data['price'] <= 0:
                    self.logger.warning(f"–£ —Ç–æ–≤–∞—Ä–∞ {product_url} –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ü–µ–Ω–∞: {product_data['price']}, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º 1")
                    product_data['price'] = 1
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                images = []
                for j, img_url in enumerate(product_data['images']):
                    if self.is_valid_image_url(img_url):
                        images.append(ProductImageCreate(
                            url=img_url,
                            is_main=(j == 0)
                        ))
                
                # –ï—Å–ª–∏ –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–ª—É—à–∫—É
                if not images:
                    images = [ProductImageCreate(
                        url="https://bunkerdoors.ru/images/no-photo.jpg",
                        is_main=True
                    )]
                
                # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π –ø—Ä–æ–¥—É–∫—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∫–∞—Ç–∞–ª–æ–≥–∞
                if not first_product_image and images:
                    first_product_image = images[0].url
                    await self.update_catalog_image(db, catalog, first_product_image)
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º slug
                product_slug = generate_slug(product_data['name'])

                description = product_data['description'] or f"–í—Ö–æ–¥–Ω–∞—è –¥–≤–µ—Ä—å {product_data['name']} –æ—Ç –ë—É–Ω–∫–µ—Ä"

                # –î–æ–±–∞–≤–ª—è–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤ –æ–ø–∏—Å–∞–Ω–∏–µ
                if product_data['characteristics']:
                    characteristics_text = []
                    for key, value in product_data['characteristics'].items():
                        if key and value:
                            characteristics_text.append(f"‚Ä¢ {key}: {value}")
                    
                    if characteristics_text:
                        description += "\n\nüìã –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:\n" + "\n".join(characteristics_text)

                
                # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞-–æ–ø–∏—Å–∞–Ω–∏–µ
                meta_description = self.create_meta_description(product_data['description'], product_data['characteristics'])
                
                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –ø—Ä–æ–¥—É–∫—Ç–∞
                product = ProductCreate(
                    name=product_data['name'],
                    price=product_data['price'],
                    discount_price=product_data['old_price'] if product_data['old_price'] > 0 else None,
                    description=description,  # –ü–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
                    catalog_id=catalog_id,
                    images=images,
                    image=images[0].url if images else None,
                    in_stock=product_data['in_stock'],
                    slug=product_slug,
                    meta_title=product_data['meta_title'] or f"{product_data['name']} - –ë—É–Ω–∫–µ—Ä",
                    meta_description=meta_description[:500],
                    brand_id=brand_id,
                    article=product_data['article']
                )
                
                products.append(product)
                self.logger.info(f"–°–æ–∑–¥–∞–Ω –ø—Ä–æ–¥—É–∫—Ç: {product.name}, —Ü–µ–Ω–∞: {product.price}")
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–æ–≤–∞—Ä–∞ {product_url}: {e}", exc_info=True)
        
        self.logger.info(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞")
        return products
    
    def extract_price_from_text(self, text: str) -> int:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–Ω—É –∏–∑ —Ç–µ–∫—Å—Ç–∞
        """
        if not text:
            return 0
        
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä –∏ –ø—Ä–æ–±–µ–ª–æ–≤
        clean_text = re.sub(r'[^\d\s]', '', text)
        
        # –ò—â–µ–º —á–∏—Å–ª–∞
        numbers = re.findall(r'\d+', clean_text)
        
        if not numbers:
            return 0
        
        # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∏—Å–µ–ª, –±–µ—Ä–µ–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ (–æ–±—ã—á–Ω–æ —ç—Ç–æ —Ü–µ–Ω–∞)
        prices = [int(num) for num in numbers if len(num) >= 3]  # –¶–µ–Ω–∞ –æ–±—ã—á–Ω–æ –±–æ–ª—å—à–µ 100
        
        return max(prices) if prices else 0
    
    def is_valid_image_url(self, url: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
        """
        if not url:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        valid_extensions = ['.jpg', '.jpeg', '.png', '.webp', '.gif']
        url_lower = url.lower()
        
        return any(ext in url_lower for ext in valid_extensions)
    
    async def assign_product_to_all_categories(self, db: AsyncSession, product_id: int, 
                                             category_matches: List[Dict], default_category_id: int):
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–µ—Ä—Å–∏—è: –ù–∞–∑–Ω–∞—á–∞–µ—Ç –ø—Ä–æ–¥—É–∫—Ç –≤–æ –≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        """
        try:
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Å–≤—è–∑–∏ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
            await self.clear_product_categories(db, product_id)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—Å–Ω–æ–≤–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            await self.add_product_to_category(db, product_id, default_category_id, is_primary=True)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            for category_match in category_matches:
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ —Å–ª–æ–≤–∞—Ä—è
                category_id = category_match['id']
                category_name = category_match['name']
                
                if category_id != default_category_id:
                    await self.add_product_to_category(db, product_id, category_id, is_primary=False)
                    self.logger.info(f"–ü—Ä–æ–¥—É–∫—Ç {product_id} –¥–æ–±–∞–≤–ª–µ–Ω –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—é '{category_name}' (ID: {category_id})")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø—Ä–æ–¥—É–∫—Ç—É {product_id}: {e}", exc_info=True)
            raise
    
    async def parse_multiple_catalogs(self, catalog_urls: List[str], db: AsyncSession) -> int:
        """
        –ü–∞—Ä—Å–∏—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞—Ç–∞–ª–æ–≥–æ–≤ (—Ç–æ—á–Ω–æ –∫–∞–∫ –≤ –õ–∞–±–∏—Ä–∏–Ω—Ç–µ)
        """
        self.logger.info(f"–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è {len(catalog_urls)} –∫–∞—Ç–∞–ª–æ–≥–æ–≤")
        total_products = 0
        new_products = 0
        updated_products = 0
        
        # –ü–æ–ª—É—á–∞–µ–º –±—Ä–µ–Ω–¥
        brand_id = await self.ensure_brand_exists(db)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∏
        await self.update_catalogs_brand_id(db, brand_id)
        
        # –®–ê–ì–ò –ü–û–î–ì–û–¢–û–í–ö–ò –ö–ê–¢–ï–ì–û–†–ò–ô
        
        # 1. –ü–æ–ª—É—á–∞–µ–º –í–°–ï –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –ë–î
        all_categories = await self.get_all_categories_from_db(db)
        
        if not all_categories:
            self.logger.error("–í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π!")
            return 0
        
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(all_categories)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ –ë–î")
        
        # 2. –ü–æ–ª—É—á–∞–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é "–í—Å–µ –¥–≤–µ—Ä–∏"
        default_category = await self.get_default_category(db)
        
        if not default_category:
            self.logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è '–í—Å–µ –¥–≤–µ—Ä–∏' –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è!")
            return 0
        
        default_category_id = default_category.id
        self.logger.info(f"–û—Å–Ω–æ–≤–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: '{default_category.name}' (ID: {default_category_id})")
        self.logger.info(f"–ë—Ä–µ–Ω–¥ –¥–ª—è –≤—Å–µ—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤: '{self.brand_name}' (ID: {brand_id})")
        
        # –ü–ê–†–°–ò–ù–ì –ò –°–û–ó–î–ê–ù–ò–ï –ü–†–û–î–£–ö–¢–û–í
        products_to_classify = []
        
        for url in catalog_urls:
            try:
                products = await self.parse_bunker_doors_products(url, db)
                self.logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(products)} –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞ {url}")
                
                for product_in in products:
                    try:
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
                        result = await db.execute(
                            select(Product).where(
                                or_(
                                    Product.slug == product_in.slug,
                                    func.lower(Product.name) == product_in.name.lower()
                                )
                            )
                        )
                        existing_product = result.scalar_one_or_none()
                        
                        # –°–æ–∑–¥–∞–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–¥—É–∫—Ç
                        created_product = await create_or_update_product(db, product_in)
                        
                        if created_product:
                            # –°–æ–±–∏—Ä–∞–µ–º –í–ï–°–¨ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
                            analysis_text = self._prepare_product_text_for_analysis(product_in)
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                            products_to_classify.append({
                                'product_id': created_product.id,
                                'text': analysis_text,
                                'name': product_in.name
                            })
                            
                            # –°—á–µ—Ç—á–∏–∫–∏
                            total_products += 1
                            if existing_product:
                                updated_products += 1
                            else:
                                new_products += 1
                                
                            await db.flush()
                        
                    except Exception as e:
                        self.logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–æ–≤–∞—Ä–∞: {e}")
                        await db.rollback()
            
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞—Ç–∞–ª–æ–≥–∞ {url}: {e}", exc_info=True)
                await db.rollback()
        
        # –ö–æ–º–º–∏—Ç–∏–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã
        try:
            await db.commit()
            self.logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {total_products} –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (–Ω–æ–≤—ã—Ö: {new_products}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {updated_products})")
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤: {e}", exc_info=True)
            await db.rollback()
            return 0
        
        # –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú
        if products_to_classify:
            self.logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é {len(products_to_classify)} –ø—Ä–æ–¥—É–∫—Ç–æ–≤")
            
            classified_count = 0
            
            for product_info in products_to_classify:
                try:
                    product_id = product_info['product_id']
                    product_text = product_info['text']
                    product_name = product_info['name']
                    
                    # –ù–∞—Ö–æ–¥–∏–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                    additional_categories = await self.classify_product_to_categories(
                        product_text, 
                        all_categories,
                        min_matches=1  # –ú–∏–Ω–∏–º—É–º 1 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                    )
                    
                    # –ù–∞–∑–Ω–∞—á–∞–µ–º –ø—Ä–æ–¥—É–∫—Ç –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤ "–í—Å–µ –¥–≤–µ—Ä–∏" + –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ)
                    await self.assign_product_to_all_categories(
                        db,
                        product_id,
                        default_category_id,
                        additional_categories
                    )
                    
                    classified_count += 1
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                    additional_names = [cat['name'] for cat in additional_categories[:3]]  # –ü–µ—Ä–≤—ã–µ 3
                    self.logger.debug(f"–ü—Ä–æ–¥—É–∫—Ç '{product_name}' -> –í—Å–µ –¥–≤–µ—Ä–∏ + {additional_names}")
                    
                except Exception as e:
                    self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–æ–¥—É–∫—Ç–∞ {product_info.get('name', 'Unknown')}: {e}")
                    continue
            
            # –ö–æ–º–º–∏—Ç–∏–º –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            try:
                await db.commit()
                self.logger.info(f"–£—Å–ø–µ—à–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ {classified_count} –ø—Ä–æ–¥—É–∫—Ç–æ–≤")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö
                await self.update_category_counters(db)
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}", exc_info=True)
                await db.rollback()
        
        self.logger.info(f"–ò–¢–û–ì–û: {total_products} —Ç–æ–≤–∞—Ä–æ–≤ (–Ω–æ–≤—ã—Ö: {new_products}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {updated_products})")
        return total_products

    def _prepare_product_text_for_analysis(self, product_in: ProductCreate) -> str:
        """
        –£–ü–†–û–©–ï–ù–û: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–¥—É–∫—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        (—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Ç–µ–ø–µ—Ä—å –≤ –æ–ø–∏—Å–∞–Ω–∏–∏)
        """
        text_parts = []
        
        # –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞ (—Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π —Ç–µ–∫—Å—Ç)
        if hasattr(product_in, 'name') and product_in.name:
            text_parts.append(product_in.name)
        
        # –û–ø–∏—Å–∞–Ω–∏–µ (—Ç–µ–ø–µ—Ä—å —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏)
        if hasattr(product_in, 'description') and product_in.description:
            text_parts.append(product_in.description)
        
        # –ú–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if hasattr(product_in, 'meta_title') and product_in.meta_title:
            text_parts.append(product_in.meta_title)
        
        if hasattr(product_in, 'meta_description') and product_in.meta_description:
            text_parts.append(product_in.meta_description)
        
        # –ê—Ä—Ç–∏–∫—É–ª (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if hasattr(product_in, 'article') and product_in.article:
            text_parts.append(product_in.article)
        
        result = " ".join(text_parts)
        self.logger.debug(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ ({len(result)} —Å–∏–º–≤–æ–ª–æ–≤): {result[:100]}...")
        return result