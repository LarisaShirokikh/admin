"""
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∫—Ä–∞–ø–µ—Ä –¥–ª—è —Å–∞–π—Ç–∞ Bunker Doors —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –∫–ª–∞—Å—Å–∞
"""
from typing import List, Dict, Any, Optional
import logging
import json
import re
from bs4 import BeautifulSoup
from sqlalchemy import func, or_, select
from sqlalchemy.ext.asyncio import AsyncSession

from app.models.product import Product
from app.schemas.product import ProductCreate
from app.schemas.product_image import ProductImageCreate
from app.utils.text_utils import generate_slug, clean_text
from app.crud.product import create_or_update_product
from app.scrapers.base_scraper import BaseScraper

logger = logging.getLogger("bunker_doors_scraper")

class BunkerDoorsScraper(BaseScraper):
    def __init__(self):
        super().__init__(
            brand_name="–ë—É–Ω–∫–µ—Ä",
            brand_slug="bunker",
            base_url="https://bunkerdoors.ru",
            logger_name="bunker_doors_scraper"
        )

    
    def extract_product_links_from_page(self, soup: BeautifulSoup, base_url: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞
        """
        product_links = []
        
        # –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã –≤ —Å–ø–∏—Å–∫–µ
        items = soup.select("li.products-list-01-item")
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
        
        for i, item in enumerate(items):
            try:
                # –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —Ç–æ–≤–∞—Ä —Ä–∞–∑–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏
                link_element = None
                
                # –°–ø–æ—Å–æ–± 1: –ò—â–µ–º —Å—Å—ã–ª–∫—É –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Ç–æ–≤–∞—Ä–∞
                img_link = item.select_one(".products-list-01-item__img a")
                if img_link and img_link.get('href'):
                    link_element = img_link
                    self.logger.info(f"–¢–æ–≤–∞—Ä {i+1}: –Ω–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ —á–µ—Ä–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
                
                # –°–ø–æ—Å–æ–± 2: –ò—â–µ–º —Å—Å—ã–ª–∫—É –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
                if not link_element:
                    title_link = item.select_one(".products-list-01-item__header a")
                    if title_link and title_link.get('href'):
                        link_element = title_link
                        self.logger.info(f"–¢–æ–≤–∞—Ä {i+1}: –Ω–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ")
                
                # –°–ø–æ—Å–æ–± 3: –ò—â–µ–º –ª—é–±—É—é —Å—Å—ã–ª–∫—É —Å href —Å–æ–¥–µ—Ä–∂–∞—â–∏–º —Ç–æ–≤–∞—Ä–Ω—ã–π –∫–æ–¥
                if not link_element:
                    all_links = item.select("a[href]")
                    for link in all_links:
                        href = link.get('href', '')
                        if any(pattern in href for pattern in ['/bn-', '/fl-', '/prod/']):
                            link_element = link
                            self.logger.info(f"–¢–æ–≤–∞—Ä {i+1}: –Ω–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É: {href}")
                            break
                
                # –°–ø–æ—Å–æ–± 4: –ü–µ—Ä–≤–∞—è —Å—Å—ã–ª–∫–∞ –≤ —ç–ª–µ–º–µ–Ω—Ç–µ (–µ—Å–ª–∏ –¥—Ä—É–≥–∏—Ö —Å–ø–æ—Å–æ–±–æ–≤ –Ω–µ—Ç)
                if not link_element:
                    first_link = item.select_one("a[href]")
                    if first_link:
                        link_element = first_link
                        self.logger.info(f"–¢–æ–≤–∞—Ä {i+1}: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–≤–∞—è —Å—Å—ã–ª–∫–∞")
                
                if link_element:
                    href = link_element.get('href')
                    if href:
                        full_url = self.normalize_url(href)
                        product_links.append(full_url)
                        self.logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ —Ç–æ–≤–∞—Ä–∞ {i+1}: {full_url}")
                    else:
                        self.logger.warning(f"–¢–æ–≤–∞—Ä {i+1}: –ø—É—Å—Ç–æ–π href")
                else:
                    self.logger.warning(f"–¢–æ–≤–∞—Ä {i+1}: –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞")
                    
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Å—Å—ã–ª–∫–∏ —Ç–æ–≤–∞—Ä–∞ {i+1}: {e}")
        
        self.logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(product_links)} —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã")
        return product_links
    
    def get_pagination_urls(self, soup: BeautifulSoup, current_url: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç URL —Å—Ç—Ä–∞–Ω–∏—Ü –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
        """
        pagination_urls = []
        
        # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
        pagination_selectors = [
            ".pagination a",
            ".pages a", 
            ".page-numbers a",
            "a[href*='page']"
        ]
        
        for selector in pagination_selectors:
            links = soup.select(selector)
            if links:
                for link in links:
                    href = link.get('href')
                    if href and href != current_url:
                        full_url = self.normalize_url(href)
                        if full_url not in pagination_urls:
                            pagination_urls.append(full_url)
                break
        
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(pagination_urls)} —Å—Ç—Ä–∞–Ω–∏—Ü –ø–∞–≥–∏–Ω–∞—Ü–∏–∏")
        return pagination_urls
    
    def parse_product_page(self, product_url: str) -> Optional[Dict[str, Any]]:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø: –ü–∞—Ä—Å–∏—Ç –æ—Ç–¥–µ–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏ –æ–ø–∏—Å–∞–Ω–∏—è
        """
        self.logger.debug(f"–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–æ–≤–∞—Ä–∞: {product_url}")
        
        html_content = self.get_html_content(product_url)
        if not html_content:
            self.logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã {product_url}")
            return None
        
        soup = BeautifulSoup(html_content, 'html.parser')
        
        try:
            product_data = {
                'url': product_url,
                'name': '',
                'price': 0,
                'old_price': 0,
                'description': '',
                'characteristics': {},
                'images': [],
                'in_stock': True,
                'article': '',
                'meta_title': '',
                'meta_description': ''
            }
            
            # 1. –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
            title_selectors = [
                "h1.product-01__title",
                ".product-title h1",
                "h1"
            ]
            
            for selector in title_selectors:
                title_elem = soup.select_one(selector)
                if title_elem:
                    product_data['name'] = clean_text(title_elem.get_text())
                    self.logger.info(f"üè∑Ô∏è –ù–∞–π–¥–µ–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–µ: {product_data['name']}")
                    break
            
            # 2. –¶–µ–Ω–∞ —Ç–æ–≤–∞—Ä–∞
            price_elem = soup.select_one(".product-01__price")
            if price_elem:
                price_text = price_elem.get_text(strip=True)
                product_data['price'] = self.extract_price_from_text(price_text)
                self.logger.info(f"üí∞ –ù–∞–π–¥–µ–Ω–∞ —Ü–µ–Ω–∞: {product_data['price']} (—Ç–µ–∫—Å—Ç: {price_text})")
            
            # 3. –°—Ç–∞—Ä–∞—è —Ü–µ–Ω–∞
            old_price_elem = soup.select_one(".product-01__old-price")
            if old_price_elem:
                old_price_text = old_price_elem.get_text(strip=True)
                product_data['old_price'] = self.extract_price_from_text(old_price_text)
                self.logger.info(f"üí∏ –ù–∞–π–¥–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è —Ü–µ–Ω–∞: {product_data['old_price']}")
            
            # 4. –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ü–ê–†–°–ò–ù–ì –û–ü–ò–°–ê–ù–ò–Ø
            description_parts = []

            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è
            desc_selectors = [
                ".product-description",
                ".product-01__description", 
                ".product-content",
                ".product-info",
                ".description",
                ".product-details",
                ".product-text"
            ]

            self.logger.info(f"üìù –ò—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞...")

            for selector in desc_selectors:
                desc_elements = soup.select(selector)
                self.logger.info(f"üìù –°–µ–ª–µ–∫—Ç–æ—Ä '{selector}': –Ω–∞–π–¥–µ–Ω–æ {len(desc_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                
                for i, desc_elem in enumerate(desc_elements):
                    if desc_elem:
                        desc_text = clean_text(desc_elem.get_text())
                        if desc_text and len(desc_text.strip()) > 10:  # –ú–∏–Ω–∏–º—É–º 10 —Å–∏–º–≤–æ–ª–æ–≤
                            description_parts.append(desc_text)
                            self.logger.info(f"üìù ‚úÖ –ù–∞–π–¥–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ #{i+1} ({len(desc_text)} —Å–∏–º–≤–æ–ª–æ–≤): {desc_text[:100]}...")
                        else:
                            self.logger.info(f"üìù ‚ùå –û–ø–∏—Å–∞–Ω–∏–µ #{i+1} —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–ª–∏ –ø—É—Å—Ç–æ–µ: '{desc_text}'")

            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ, –∏—â–µ–º –≤ –æ–±—â–∏—Ö –±–ª–æ–∫–∞—Ö
            if not description_parts:
                self.logger.warning(f"üìù –û—Å–Ω–æ–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –Ω–µ –¥–∞–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞, –∏—â–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è")
                
                # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                alt_desc_selectors = [
                    ".product .content",
                    ".product .text", 
                    "article",
                    ".main-content p",
                    ".product-wrapper .text"
                ]
                
                for alt_selector in alt_desc_selectors:
                    alt_elements = soup.select(alt_selector)
                    self.logger.info(f"üìù –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä '{alt_selector}': –Ω–∞–π–¥–µ–Ω–æ {len(alt_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                    
                    for elem in alt_elements:
                        alt_text = clean_text(elem.get_text())
                        if alt_text and len(alt_text.strip()) > 20:
                            description_parts.append(alt_text)
                            self.logger.info(f"üìù ‚úÖ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ: {alt_text[:100]}...")
                            break
                    
                    if description_parts:
                        break

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞—Å—Ç–∏ –æ–ø–∏—Å–∞–Ω–∏—è
            final_description = " ".join(description_parts).strip()
            product_data['description'] = final_description

            self.logger.info(f"üìù –ò–¢–û–ì–û –æ–ø–∏—Å–∞–Ω–∏–µ ({len(final_description)} —Å–∏–º–≤–æ–ª–æ–≤): {final_description[:200]}...")

            if not final_description:
                self.logger.warning(f"üìù ‚ùå –û–ü–ò–°–ê–ù–ò–ï –ù–ï –ù–ê–ô–î–ï–ù–û!")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                main_blocks = soup.select(".product, .main, .content, article")
                self.logger.info(f"üìù –û—Å–Ω–æ–≤–Ω—ã–µ –±–ª–æ–∫–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {len(main_blocks)}")
                for i, block in enumerate(main_blocks[:3]):
                    block_text = clean_text(block.get_text())
                    if block_text:
                        self.logger.info(f"üìù –ë–ª–æ–∫ {i+1} ({len(block_text)} —Å–∏–º–≤–æ–ª–æ–≤): {block_text[:150]}...")
            else:
                self.logger.info(f"üìù ‚úÖ –û–ø–∏—Å–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ")
            
            # 5. –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –ü–ê–†–°–ò–ù–ì –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö
            characteristics = {}
            param_items = soup.select(".product-01__parameters-item")
            self.logger.info(f"‚öôÔ∏è –ù–∞–π–¥–µ–Ω–æ {len(param_items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫")

            for i, item in enumerate(param_items):
                self.logger.info(f"‚öôÔ∏è –≠–ª–µ–º–µ–Ω—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ {i+1}: {str(item)[:200]}...")
                
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞ –∏ –æ–ø–∏—Å–∞–Ω–∏—è
                term_selectors = [
                    ".product-01__parameters-item-term",
                    ".parameters-item-term", 
                    ".term",
                    "dt"
                ]
                
                desc_selectors = [
                    ".product-01__parameters-item-desc",
                    ".parameters-item-desc",
                    ".desc", 
                    "dd"
                ]
                
                term_elem = None
                desc_elem = None
                
                # –ò—â–µ–º —Ç–µ—Ä–º–∏–Ω
                for term_selector in term_selectors:
                    term_elem = item.select_one(term_selector)
                    if term_elem:
                        self.logger.info(f"‚öôÔ∏è –¢–µ—Ä–º–∏–Ω –Ω–∞–π–¥–µ–Ω —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä '{term_selector}'")
                        break
                
                # –ò—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
                for desc_selector in desc_selectors:
                    desc_elem = item.select_one(desc_selector)
                    if desc_elem:
                        self.logger.info(f"‚öôÔ∏è –û–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä '{desc_selector}'")
                        break
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ –≤—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
                if not term_elem or not desc_elem:
                    self.logger.info(f"‚öôÔ∏è –°–µ–ª–µ–∫—Ç–æ—Ä—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥")
                    
                    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞
                    full_text = clean_text(item.get_text())
                    self.logger.info(f"‚öôÔ∏è –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞: '{full_text}'")
                    
                    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ –¥–≤–æ–µ—Ç–æ—á–∏—é –∏–ª–∏ –¥—Ä—É–≥–∏–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º
                    if ':' in full_text:
                        parts = full_text.split(':', 1)
                        if len(parts) == 2:
                            key = clean_text(parts[0])
                            value = clean_text(parts[1])
                            if key and value:
                                characteristics[key] = value
                                self.logger.info(f"‚öôÔ∏è –ò–∑–≤–ª–µ—á–µ–Ω–æ —á–µ—Ä–µ–∑ –¥–≤–æ–µ—Ç–æ—á–∏–µ: '{key}' = '{value}'")
                            continue
                    
                    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —É–∑–ª—ã
                    text_nodes = []
                    for child in item.descendants:
                        if hasattr(child, 'string') and child.string and child.string.strip():
                            text_content = clean_text(child.string)
                            if text_content and len(text_content) > 1:
                                text_nodes.append(text_content)
                    
                    self.logger.info(f"‚öôÔ∏è –ù–∞–π–¥–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —É–∑–ª–æ–≤: {text_nodes}")
                    
                    if len(text_nodes) >= 2:
                        key = text_nodes[0]
                        value = ' '.join(text_nodes[1:])
                        if key and value:
                            characteristics[key] = value
                            self.logger.info(f"‚öôÔ∏è –ò–∑–≤–ª–µ—á–µ–Ω–æ –∏–∑ —É–∑–ª–æ–≤: '{key}' = '{value}'")
                    continue
                
                # –û–±—ã—á–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                if term_elem and desc_elem:
                    key = clean_text(term_elem.get_text())
                    value = clean_text(desc_elem.get_text())
                    
                    self.logger.info(f"‚öôÔ∏è –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ: —Ç–µ—Ä–º–∏–Ω='{term_elem.get_text()}', –æ–ø–∏—Å–∞–Ω–∏–µ='{desc_elem.get_text()}'")
                    self.logger.info(f"‚öôÔ∏è –û—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: –∫–ª—é—á='{key}', –∑–Ω–∞—á–µ–Ω–∏–µ='{value}'")
                    
                    if key and value:
                        characteristics[key] = value
                        self.logger.info(f"‚öôÔ∏è ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞: '{key}' = '{value}'")
                    else:
                        self.logger.warning(f"‚öôÔ∏è ‚ùå –ü—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏")

            product_data['characteristics'] = characteristics
            self.logger.info(f"‚öôÔ∏è –ò–¢–û–ì–û –∏–∑–≤–ª–µ—á–µ–Ω–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {len(characteristics)}")

            # –í—ã–≤–æ–¥–∏–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            if characteristics:
                self.logger.info(f"‚öôÔ∏è –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫:")
                for key, value in characteristics.items():
                    self.logger.info(f"‚öôÔ∏è   ‚Ä¢ {key}: {value}")
            else:
                self.logger.warning(f"‚öôÔ∏è –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –ù–ï –Ω–∞–π–¥–µ–Ω—ã!")
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞ - –∏—â–µ–º –í–°–ï –≤–æ–∑–º–æ–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
                self.logger.info(f"‚öôÔ∏è –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫...")
                
                # –ò—â–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                alt_selectors = [
                    ".parameters li",
                    ".product-parameters .item", 
                    ".characteristics .row",
                    ".specs dt, .specs dd",
                    "dl dt, dl dd"
                ]
                
                for alt_selector in alt_selectors:
                    alt_elements = soup.select(alt_selector)
                    if alt_elements:
                        self.logger.info(f"‚öôÔ∏è –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä '{alt_selector}': –Ω–∞–π–¥–µ–Ω–æ {len(alt_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                        for j, elem in enumerate(alt_elements[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                            self.logger.info(f"‚öôÔ∏è –≠–ª–µ–º–µ–Ω—Ç {j+1}: {clean_text(elem.get_text())}")
                        break
            
            # 6. –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø - –Ω–æ–≤—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –ø–æ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ HTML
            images = []
            
            self.logger.info(f"üñºÔ∏è === –ù–ê–ß–ò–ù–ê–ï–ú –ü–û–ò–°–ö –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô –¥–ª—è {product_url} ===")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≥–∞–ª–µ—Ä–µ–∏ –≤ HTML
            gallery_check = soup.select(".product-gallery-04")
            self.logger.info(f"üñºÔ∏è –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ .product-gallery-04: {len(gallery_check)}")
            
            if gallery_check:
                gallery_html = str(gallery_check[0])[:500]
                self.logger.info(f"üñºÔ∏è HTML –≥–∞–ª–µ—Ä–µ–∏ (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {gallery_html}")
            
            # –ú–µ—Ç–æ–¥ 1: –ì–ª–∞–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
            main_containers = soup.select(".product-gallery-04__stage-item-img-container")
            self.logger.info(f"üñºÔ∏è –ì–ª–∞–≤–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤: {len(main_containers)}")
            
            for i, container in enumerate(main_containers):
                href = container.get('href')
                self.logger.info(f"üñºÔ∏è –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä {i+1}: href='{href}'")
                
                if href:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—ã—Ä–æ–π href
                    self.logger.info(f"üñºÔ∏è –°—ã—Ä–æ–π href: '{href}'")
                    
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL
                    if href.startswith('/'):
                        full_url = f"https://bunkerdoors.ru{href}"
                    elif href.startswith('http'):
                        full_url = href
                    else:
                        full_url = f"https://bunkerdoors.ru/{href}"
                    
                    self.logger.info(f"üñºÔ∏è –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π URL: '{full_url}'")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
                    if self._debug_is_valid_image_url(full_url):
                        images.append(full_url)
                        self.logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –≥–ª–∞–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {full_url}")
                    else:
                        self.logger.warning(f"‚ùå –ì–ª–∞–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –ø—Ä–æ—à–ª–æ –≤–∞–ª–∏–¥–∞—Ü–∏—é: {full_url}")
            
            # –ú–µ—Ç–æ–¥ 2: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –≥–∞–ª–µ—Ä–µ–∏ (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô)
            gallery_img_selectors = [
                ".product-gallery-04__item img",
                ".product-gallery-04__stage-item img", 
                ".product-gallery img",
                ".gallery img"
            ]
            
            for selector in gallery_img_selectors:
                gallery_images = soup.select(selector)
                self.logger.info(f"üñºÔ∏è –°–µ–ª–µ–∫—Ç–æ—Ä '{selector}': –Ω–∞–π–¥–µ–Ω–æ {len(gallery_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                
                for i, img in enumerate(gallery_images):
                    self.logger.info(f"üñºÔ∏è IMG {i+1} –∞—Ç—Ä–∏–±—É—Ç—ã: {dict(img.attrs)}")
                    
                    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ lazy loading –∞—Ç—Ä–∏–±—É—Ç–æ–≤
                    img_url = None
                    
                    # –°–ø–æ—Å–æ–± 1: –û–±—ä–µ–¥–∏–Ω—è–µ–º data-bc-lazy-path + data-bc-lazy-filename
                    lazy_path = img.get('data-bc-lazy-path')
                    lazy_filename = img.get('data-bc-lazy-filename')
                    
                    if lazy_path and lazy_filename:
                        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–ª–µ—à–∏ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º
                        lazy_path = lazy_path.rstrip('/')
                        img_url = f"{lazy_path}/{lazy_filename}"
                        self.logger.info(f"üñºÔ∏è –°–æ–±—Ä–∞–Ω–æ –∏–∑ lazy: {lazy_path} + {lazy_filename} = {img_url}")
                    
                    # –°–ø–æ—Å–æ–± 2: –ü—Ä—è–º—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã (–µ—Å–ª–∏ lazy –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª)
                    if not img_url:
                        for attr in ['src', 'data-src', 'data-original']:
                            attr_value = img.get(attr)
                            if attr_value and not attr_value.startswith('data:'):  # –ò—Å–∫–ª—é—á–∞–µ–º SVG –∑–∞–≥–ª—É—à–∫–∏
                                img_url = attr_value
                                self.logger.info(f"üñºÔ∏è –ù–∞–π–¥–µ–Ω –∞—Ç—Ä–∏–±—É—Ç {attr}: '{img_url}'")
                                break
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–π URL
                    if img_url:
                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL
                        if img_url.startswith('/'):
                            full_url = f"https://bunkerdoors.ru{img_url}"
                        elif img_url.startswith('http'):
                            full_url = img_url
                        else:
                            full_url = f"https://bunkerdoors.ru/{img_url}"
                        
                        self.logger.info(f"üñºÔ∏è –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π URL: '{full_url}'")
                        
                        # –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–∞–ª–∏–¥–∞—Ü–∏—è (–∏—Å–∫–ª—é—á–∞–µ–º –ø–∞–ø–∫–∏)
                        if self._debug_is_valid_image_url(full_url) and full_url not in images:
                            images.append(full_url)
                            self.logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {full_url}")
                        else:
                            self.logger.warning(f"‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –ø—Ä–æ—à–ª–æ –≤–∞–ª–∏–¥–∞—Ü–∏—é: {full_url}")
                
                # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –ø–æ–∏—Å–∫
                if images:
                    self.logger.info(f"üñºÔ∏è –ù–∞—à–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä '{selector}', –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –ø–æ–∏—Å–∫")
                    break
            
            # –ú–µ—Ç–æ–¥ 3: –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ (–µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏)
            if not images:
                self.logger.warning("üñºÔ∏è –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã –Ω–µ –¥–∞–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞, –∏—â–µ–º –í–°–ï –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                
                all_images = soup.find_all('img')
                self.logger.info(f"üñºÔ∏è –í—Å–µ–≥–æ IMG —Ç–µ–≥–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {len(all_images)}")
                
                for i, img in enumerate(all_images):
                    img_attrs = dict(img.attrs)
                    self.logger.info(f"üñºÔ∏è –ì–ª–æ–±–∞–ª—å–Ω–æ–µ IMG {i+1}: {img_attrs}")
                    
                    # –ò—â–µ–º –ª—é–±—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
                    for attr_name, attr_value in img_attrs.items():
                        if isinstance(attr_value, str) and ('/images/' in attr_value or 'product' in attr_value.lower()):
                            if attr_value.startswith('/'):
                                full_url = f"https://bunkerdoors.ru{attr_value}"
                            else:
                                full_url = attr_value
                            
                            if self._debug_is_valid_image_url(full_url) and full_url not in images:
                                images.append(full_url)
                                self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –≥–ª–æ–±–∞–ª—å–Ω—ã–º –ø–æ–∏—Å–∫–æ–º: {full_url}")
            
            product_data['images'] = images
            self.logger.info(f"üéØ –ò–¢–û–ì–û –ù–ê–ô–î–ï–ù–û –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô: {len(images)}")
            
            if images:
                for i, img in enumerate(images):
                    self.logger.info(f"   {i+1}. {img}")
            else:
                self.logger.error(f"‚ùå –ù–ò –û–î–ù–û–ì–û –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø –ù–ï –ù–ê–ô–î–ï–ù–û –¥–ª—è {product_url}")
            
            # 7. –ê—Ä—Ç–∏–∫—É–ª —Ç–æ–≤–∞—Ä–∞
            article_elem = soup.select_one(".product-01__article")
            if article_elem:
                article_text = clean_text(article_elem.get_text())
                article_match = re.search(r'([A-Za-z0-9\-]+)', article_text)
                if article_match:
                    product_data['article'] = article_match.group(1)
                    self.logger.info(f"üè∑Ô∏è –ù–∞–π–¥–µ–Ω –∞—Ä—Ç–∏–∫—É–ª: {product_data['article']}")
            
            # 8. –ù–∞–ª–∏—á–∏–µ —Ç–æ–≤–∞—Ä–∞
            in_stock = True
            page_text = soup.get_text().lower()
            if any(phrase in page_text for phrase in ['–Ω–µ—Ç –≤ –Ω–∞–ª–∏—á–∏–∏', '–ø–æ–¥ –∑–∞–∫–∞–∑', '–Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω']):
                in_stock = False
            
            product_data['in_stock'] = in_stock
            self.logger.info(f"üì¶ –í –Ω–∞–ª–∏—á–∏–∏: {in_stock}")
            
            # 9. –ú–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            title_tag = soup.select_one("title")
            if title_tag:
                product_data['meta_title'] = clean_text(title_tag.get_text())
            
            meta_desc = soup.select_one("meta[name='description']")
            if meta_desc:
                product_data['meta_description'] = meta_desc.get('content', '')
            
            self.logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è: {product_data['name']}")
            return product_data
            
        except Exception as e:
            self.logger.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ç–æ–≤–∞—Ä–∞ {product_url}: {e}", exc_info=True)
            return None

    def _debug_is_valid_image_url(self, url: str) -> bool:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–∞–ª–∏–¥–∞—Ü–∏—è URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –ø–∞–ø–æ–∫
        """
        if not url:
            self.logger.debug(f"üîç URL –ø—É—Å—Ç–æ–π")
            return False
        
        url_lower = url.lower()
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 1: –ò—Å–∫–ª—é—á–∞–µ–º –ø–∞–ø–∫–∏ (URL –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—â–∏–µ—Å—è –Ω–∞ /)
        if url.endswith('/'):
            self.logger.info(f"üîç URL –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ '/' - —ç—Ç–æ –ø–∞–ø–∫–∞, –Ω–µ —Ñ–∞–π–ª: {url}")
            return False
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 2: –ò—Å–∫–ª—é—á–∞–µ–º SVG –∑–∞–≥–ª—É—à–∫–∏
        if 'data:image/svg+xml' in url:
            self.logger.info(f"üîç URL —Å–æ–¥–µ—Ä–∂–∏—Ç SVG –∑–∞–≥–ª—É—à–∫—É: {url}")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        valid_extensions = ['.jpg', '.jpeg', '.png', '.webp', '.gif']
        has_extension = any(url_lower.endswith(ext) for ext in valid_extensions)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        has_images_path = '/images/' in url_lower
        has_product = 'product' in url_lower
        
        # –ò—Å–∫–ª—é—á–µ–Ω–∏—è
        excluded_patterns = ['no-photo', 'placeholder', 'icon', 'logo', 'thumb', 'sprite']
        is_excluded = any(pattern in url_lower for pattern in excluded_patterns)
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
        is_long_enough = len(url) > 20  # –£–≤–µ–ª–∏—á–∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 3: –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è - —Ç—Ä–µ–±—É–µ–º –ª–∏–±–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ, –ª–∏–±–æ /images/ –≤ –ø—É—Ç–∏
        result = (has_extension or has_images_path) and not is_excluded and is_long_enough
        
        self.logger.info(f"üîç –í–∞–ª–∏–¥–∞—Ü–∏—è '{url}': ext={has_extension}, images={has_images_path}, product={has_product}, excluded={is_excluded}, long={is_long_enough} -> {result}")
        
        return result
    
    async def parse_bunker_doors_products(self, catalog_url: str, db: AsyncSession) -> List[ProductCreate]:
        """
        –ü–∞—Ä—Å–∏—Ç —Ç–æ–≤–∞—Ä—ã —Å —Å–∞–π—Ç–∞ Bunker Doors –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–∞—Ç–∞–ª–æ–≥–∞
        """
        self.logger.info(f"–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è –∫–∞—Ç–∞–ª–æ–≥–∞ {catalog_url}")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL
        catalog_url = self.normalize_url(catalog_url)
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥ –∏–∑ URL
        catalog_slug = catalog_url.rstrip('/').split('/')[-1]
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è –∫–∞—Ç–∞–ª–æ–≥–∞
        catalog_name_part = catalog_slug.replace('-', ' ').title()
        catalog_name = f"–í—Ö–æ–¥–Ω—ã–µ –¥–≤–µ—Ä–∏ –ë—É–Ω–∫–µ—Ä {catalog_name_part}"
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥
        brand_id = await self.ensure_brand_exists(db)
        await db.commit()
        catalog = await self.get_or_create_catalog(db, catalog_name, catalog_slug, brand_id)
        await db.commit()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–∞—Ç–∞–ª–æ–≥ —Å–æ–∑–¥–∞–Ω –∏ –∏–º–µ–µ—Ç ID
        if not catalog or catalog.id is None:
            self.logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∫–∞—Ç–∞–ª–æ–≥ –¥–ª—è {catalog_url}")
            return []
            
        catalog_id = catalog.id
        self.logger.info(f"–ü–æ–ª—É—á–µ–Ω –∫–∞—Ç–∞–ª–æ–≥ —Å ID: {catalog_id}")

        from app.models.catalog import Catalog
        result = await db.execute(select(Catalog).where(Catalog.id == catalog_id))
        catalog_check = result.scalar_one_or_none()
        
        if not catalog_check:
            self.logger.error(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ö–∞—Ç–∞–ª–æ–≥ —Å ID {catalog_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è!")
            return []
        
        self.logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—Ç–∞–ª–æ–≥–∞ –ø—Ä–æ–π–¥–µ–Ω–∞: '{catalog_check.name}' —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –ë–î")

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã (–≤–∫–ª—é—á–∞—è –ø–∞–≥–∏–Ω–∞—Ü–∏—é)
        all_product_links = []
        processed_urls = set()
        urls_to_process = [catalog_url]
        
        while urls_to_process:
            current_url = urls_to_process.pop(0)
            
            if current_url in processed_urls:
                continue
                
            processed_urls.add(current_url)
            
            self.logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {current_url}")
            
            # –ü–æ–ª—É—á–∞–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞
            html_content = self.get_html_content(current_url)
            if not html_content:
                self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_url}")
                continue
                
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã
            product_links = self.extract_product_links_from_page(soup, self.base_url)
            all_product_links.extend(product_links)
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            pagination_urls = self.get_pagination_urls(soup, current_url)
            for page_url in pagination_urls:
                if page_url not in processed_urls:
                    urls_to_process.append(page_url)
        
        if not all_product_links:
            self.logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã –≤ –∫–∞—Ç–∞–ª–æ–≥–µ {catalog_url}")
            return []
        
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(all_product_links)} —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã")
        
        products = []
        first_product_image = None  # –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞
        
        # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—ã–π —Ç–æ–≤–∞—Ä –æ—Ç–¥–µ–ª—å–Ω–æ
        for i, product_url in enumerate(all_product_links):
            try:
                self.logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–≤–∞—Ä {i+1}/{len(all_product_links)}: {product_url}")
                
                # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞
                product_data = self.parse_product_page(product_url)
                
                if not product_data:
                    self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–ø–∞—Ä—Å–∏—Ç—å —Ç–æ–≤–∞—Ä {product_url}")
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                if not product_data['name']:
                    self.logger.warning(f"–£ —Ç–æ–≤–∞—Ä–∞ {product_url} –Ω–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    continue
                
                if product_data['price'] <= 0:
                    self.logger.warning(f"–£ —Ç–æ–≤–∞—Ä–∞ {product_url} –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ü–µ–Ω–∞: {product_data['price']}, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º 1")
                    product_data['price'] = 1
                
                # üì∏ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –ü–û–î–ì–û–¢–û–í–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô
                images = []
                valid_image_urls = []

                # –°–Ω–∞—á–∞–ª–∞ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –∏ –ª–æ–≥–∏—Ä—É–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ URL
                self.logger.info(f"üì∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Ç–æ–≤–∞—Ä–∞ '{product_data['name']}'")
                self.logger.info(f"üì∏ –°—ã—Ä—ã–µ URL –∏–∑ –ø–∞—Ä—Å–µ—Ä–∞: {product_data['images']}")

                for j, img_url in enumerate(product_data['images']):
                    if img_url and isinstance(img_url, str):
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ URL
                        cleaned_url = img_url.strip()
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –µ—â–µ —Ä–∞–∑
                        if self.is_valid_image_url(cleaned_url):
                            valid_image_urls.append(cleaned_url)
                            self.logger.info(f"üì∏ –í–∞–ª–∏–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {j+1}: {cleaned_url}")
                        else:
                            self.logger.warning(f"üì∏ –ù–µ–≤–∞–ª–∏–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {j+1}: {cleaned_url}")
                    else:
                        self.logger.warning(f"üì∏ –ü—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL {j+1}: {img_url}")

                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç—ã ProductImageCreate —Ç–æ–ª—å–∫–æ –∏–∑ –≤–∞–ª–∏–¥–Ω—ã—Ö URL
                for j, img_url in enumerate(valid_image_urls):
                    try:
                        image_obj = ProductImageCreate(
                            url=img_url,
                            is_main=(j == 0)
                        )
                        images.append(image_obj)
                        self.logger.info(f"üì∏ –°–æ–∑–¥–∞–Ω –æ–±—ä–µ–∫—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {j+1}: {img_url} (–≥–ª–∞–≤–Ω–æ–µ: {j == 0})")
                    except Exception as e:
                        self.logger.error(f"üì∏ –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è {img_url}: {e}")

                # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                self.logger.info(f"üì∏ –ò–¢–û–ì–û —Å–æ–∑–¥–∞–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(images)}")

                if not images:
                    # –ï—Å–ª–∏ –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–ª—É—à–∫—É
                    self.logger.warning(f"üì∏ –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–ª—É—à–∫—É")
                    placeholder_url = "https://bunkerdoors.ru/images/no-photo.jpg"
                    images = [ProductImageCreate(
                        url=placeholder_url,
                        is_main=True
                    )]
                    self.logger.info(f"üì∏ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∑–∞–≥–ª—É—à–∫–∞: {placeholder_url}")

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∫–∞—Ç–∞–ª–æ–≥–∞
                if not first_product_image and images and images[0].url != "https://bunkerdoors.ru/images/no-photo.jpg":
                    first_product_image = images[0].url
                    try:
                        await self.update_catalog_image(db, catalog, first_product_image)
                        self.logger.info(f"üì∏ –û–±–Ω–æ–≤–ª–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∞: {first_product_image}")
                    except Exception as e:
                        self.logger.error(f"üì∏ –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞: {e}")
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º slug
                product_slug = generate_slug(product_data['name'])

                base_description = product_data['description'] or f"–í—Ö–æ–¥–Ω–∞—è –¥–≤–µ—Ä—å {product_data['name']} –æ—Ç –ë—É–Ω–∫–µ—Ä"

                self.logger.info(f"üìù –ë–∞–∑–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ ({len(base_description)} —Å–∏–º–≤–æ–ª–æ–≤): {base_description[:150]}...")
                self.logger.info(f"üìù –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è: {len(product_data['characteristics'])}")

                # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
                description_parts = [base_description]

                # –î–æ–±–∞–≤–ª—è–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤ –æ–ø–∏—Å–∞–Ω–∏–µ –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                if product_data['characteristics']:
                    characteristics_text = []
                    
                    self.logger.info(f"üìù –î–æ–±–∞–≤–ª—è–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤ –æ–ø–∏—Å–∞–Ω–∏–µ:")
                    for key, value in product_data['characteristics'].items():
                        if key and value and len(str(key).strip()) > 0 and len(str(value).strip()) > 0:
                            char_line = f"‚Ä¢ {str(key).strip()}: {str(value).strip()}"
                            characteristics_text.append(char_line)
                            self.logger.info(f"üìù   {char_line}")
                    
                    if characteristics_text:
                        char_section = "\n\nüìã –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:\n" + "\n".join(characteristics_text)
                        description_parts.append(char_section)
                        self.logger.info(f"üìù ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ —Å–µ–∫—Ü–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ ({len(char_section)} —Å–∏–º–≤–æ–ª–æ–≤)")
                    else:
                        self.logger.warning(f"üìù ‚ùå –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –ø—É—Å—Ç—ã –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
                else:
                    self.logger.warning(f"üìù ‚ùå –ù–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è")

                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞—Å—Ç–∏
                description = "\n".join(description_parts)

                self.logger.info(f"üìù –ò–¢–û–ì–û–í–û–ï –û–ü–ò–°–ê–ù–ò–ï ({len(description)} —Å–∏–º–≤–æ–ª–æ–≤):")
                self.logger.info(f"üìù {description[:300]}..." if len(description) > 300 else f"üìù {description}")

                # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞-–æ–ø–∏—Å–∞–Ω–∏–µ
                meta_description = self.create_meta_description(
                    product_data['description'], 
                    product_data['characteristics']
                )
                
                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –ø—Ä–æ–¥—É–∫—Ç–∞
                product = ProductCreate(
                    name=product_data['name'],
                    price=product_data['price'],
                    discount_price=product_data['old_price'] if product_data['old_price'] > 0 else None,
                    description=description,  # –ü–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
                    catalog_id=catalog_id,
                    images=images,  # ‚Üê –ü–µ—Ä–µ–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ ProductImageCreate
                    image=images[0].url if images else None,  # ‚Üê –ì–ª–∞–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    in_stock=product_data['in_stock'],
                    slug=product_slug,
                    meta_title=product_data['meta_title'] or f"{product_data['name']} - –ë—É–Ω–∫–µ—Ä",
                    meta_description=meta_description[:500],
                    brand_id=brand_id,
                    article=product_data['article']
                )
                
                products.append(product)
                self.logger.info(f"üì∏ –°–æ–∑–¥–∞–Ω –ø—Ä–æ–¥—É–∫—Ç —Å {len(product.images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏: {product.name}, —Ü–µ–Ω–∞: {product.price}")
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–æ–≤–∞—Ä–∞ {product_url}: {e}", exc_info=True)
        
        self.logger.info(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞")
        return products
    
    # –í–ê–ñ–ù–û: –ú–µ—Ç–æ–¥ parse_multiple_catalogs –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ –ü–†–ê–í–ò–õ–¨–ù–û–ú —É—Ä–æ–≤–Ω–µ –æ—Ç—Å—Ç—É–ø–æ–≤!
    async def parse_multiple_catalogs(self, catalog_urls: List[str], db: AsyncSession) -> int:
        """
        –ü–∞—Ä—Å–∏—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞—Ç–∞–ª–æ–≥–æ–≤ (–ü–ï–†–ï–û–ü–†–ï–î–ï–õ–ï–ù –º–µ—Ç–æ–¥ –∏–∑ BaseScraper)
        """
        self.logger.info(f"–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è {len(catalog_urls)} –∫–∞—Ç–∞–ª–æ–≥–æ–≤")
        total_products = 0
        new_products = 0
        updated_products = 0
        
        # –ü–æ–ª—É—á–∞–µ–º –±—Ä–µ–Ω–¥
        brand_id = await self.ensure_brand_exists(db)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∏
        await self.update_catalogs_brand_id(db, brand_id)
        
        # –®–ê–ì–ò –ü–û–î–ì–û–¢–û–í–ö–ò –ö–ê–¢–ï–ì–û–†–ò–ô
        
        # 1. –ü–æ–ª—É—á–∞–µ–º –í–°–ï –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –ë–î
        all_categories = await self.get_all_categories_from_db(db)
        
        if not all_categories:
            self.logger.error("–í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π!")
            return 0
        
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(all_categories)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ –ë–î")
        
        # 2. –ü–æ–ª—É—á–∞–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é "–í—Å–µ –¥–≤–µ—Ä–∏"
        default_category = await self.get_default_category(db)
        
        if not default_category:
            self.logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è '–í—Å–µ –¥–≤–µ—Ä–∏' –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è!")
            return 0
        
        default_category_id = default_category.id
        self.logger.info(f"–û—Å–Ω–æ–≤–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: '{default_category.name}' (ID: {default_category_id})")
        self.logger.info(f"–ë—Ä–µ–Ω–¥ –¥–ª—è –≤—Å–µ—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤: '{self.brand_name}' (ID: {brand_id})")
        
        # –ü–ê–†–°–ò–ù–ì –ò –°–û–ó–î–ê–ù–ò–ï –ü–†–û–î–£–ö–¢–û–í
        products_to_classify = []
        
        for url in catalog_urls:
            try:
                products = await self.parse_bunker_doors_products(url, db)
                self.logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(products)} –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞ {url}")
                
                for product_in in products:
                    try:
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
                        result = await db.execute(
                            select(Product).where(
                                or_(
                                    Product.slug == product_in.slug,
                                    func.lower(Product.name) == product_in.name.lower()
                                )
                            )
                        )
                        existing_product = result.scalar_one_or_none()
                        
                        # –°–æ–∑–¥–∞–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–¥—É–∫—Ç
                        created_product = await create_or_update_product(db, product_in)
                        
                        if created_product:
                            # –°–æ–±–∏—Ä–∞–µ–º –í–ï–°–¨ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
                            analysis_text = self._prepare_product_text_for_analysis(product_in)
                            
                            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                            products_to_classify.append({
                                'product_id': created_product.id,
                                'text': analysis_text,
                                'name': product_in.name
                            })
                            
                            # –°—á–µ—Ç—á–∏–∫–∏
                            total_products += 1
                            if existing_product:
                                updated_products += 1
                            else:
                                new_products += 1
                                
                            await db.flush()
                        
                    except Exception as e:
                        self.logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–æ–≤–∞—Ä–∞: {e}")
                        await db.rollback()
            
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞—Ç–∞–ª–æ–≥–∞ {url}: {e}", exc_info=True)
                await db.rollback()
        
        # –ö–æ–º–º–∏—Ç–∏–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã
        try:
            await db.commit()
            self.logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {total_products} –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (–Ω–æ–≤—ã—Ö: {new_products}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {updated_products})")
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤: {e}", exc_info=True)
            await db.rollback()
            return 0
        
        # –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú
        if products_to_classify:
            self.logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é {len(products_to_classify)} –ø—Ä–æ–¥—É–∫—Ç–æ–≤")
            
            classified_count = 0
            
            for product_info in products_to_classify:
                try:
                    product_id = product_info['product_id']
                    product_text = product_info['text']
                    product_name = product_info['name']
                    
                    # –ù–∞—Ö–æ–¥–∏–º –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                    additional_categories = await self.classify_product_to_categories(
                        product_text, 
                        all_categories,
                        min_matches=1  # –ú–∏–Ω–∏–º—É–º 1 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                    )
                    
                    # –ù–∞–∑–Ω–∞—á–∞–µ–º –ø—Ä–æ–¥—É–∫—Ç –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤ "–í—Å–µ –¥–≤–µ—Ä–∏" + –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ)
                    await self.assign_product_to_all_categories(
                        db,
                        product_id,
                        default_category_id,
                        additional_categories
                    )
                    
                    classified_count += 1
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                    additional_names = [cat['name'] for cat in additional_categories[:3]]  # –ü–µ—Ä–≤—ã–µ 3
                    self.logger.debug(f"–ü—Ä–æ–¥—É–∫—Ç '{product_name}' -> –í—Å–µ –¥–≤–µ—Ä–∏ + {additional_names}")
                    
                except Exception as e:
                    self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–æ–¥—É–∫—Ç–∞ {product_info.get('name', 'Unknown')}: {e}")
                    continue
            
            # –ö–æ–º–º–∏—Ç–∏–º –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            try:
                await db.commit()
                self.logger.info(f"–£—Å–ø–µ—à–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ {classified_count} –ø—Ä–æ–¥—É–∫—Ç–æ–≤")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö
                await self.update_category_counters(db)
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}", exc_info=True)
                await db.rollback()
        
        self.logger.info(f"–ò–¢–û–ì–û: {total_products} —Ç–æ–≤–∞—Ä–æ–≤ (–Ω–æ–≤—ã—Ö: {new_products}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {updated_products})")
        return total_products

    def extract_price_from_text(self, text: str) -> int:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–Ω—É –∏–∑ —Ç–µ–∫—Å—Ç–∞
        """
        if not text:
            return 0
        
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä –∏ –ø—Ä–æ–±–µ–ª–æ–≤
        clean_text = re.sub(r'[^\d\s]', '', text)
        
        # –ò—â–µ–º —á–∏—Å–ª–∞
        numbers = re.findall(r'\d+', clean_text)
        
        if not numbers:
            return 0
        
        # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∏—Å–µ–ª, –±–µ—Ä–µ–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ (–æ–±—ã—á–Ω–æ —ç—Ç–æ —Ü–µ–Ω–∞)
        prices = [int(num) for num in numbers if len(num) >= 3]  # –¶–µ–Ω–∞ –æ–±—ã—á–Ω–æ –±–æ–ª—å—à–µ 100
        
        return max(prices) if prices else 0
    
    def is_valid_image_url(self, url: str) -> bool:
        """–û–±—ã—á–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if not url or not isinstance(url, str):
            return False
        
        url = url.strip()
        url_lower = url.lower()
        
        # –ò—Å–∫–ª—é—á–∞–µ–º –ø–∞–ø–∫–∏ (URL –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—â–∏–µ—Å—è –Ω–∞ /)
        if url.endswith('/'):
            return False
        
        # –ò—Å–∫–ª—é—á–∞–µ–º SVG –∑–∞–≥–ª—É—à–∫–∏
        if 'data:image/svg+xml' in url:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        valid_extensions = ['.jpg', '.jpeg', '.png', '.webp', '.gif']
        has_extension = any(url_lower.endswith(ext) for ext in valid_extensions)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        has_images_path = '/images/' in url_lower
        
        # –ò—Å–∫–ª—é—á–µ–Ω–∏—è
        excluded_patterns = ['no-photo', 'placeholder', 'icon', 'logo', 'thumb', 'sprite']
        is_excluded = any(pattern in url_lower for pattern in excluded_patterns)
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
        is_long_enough = len(url) > 20
        
        return (has_extension or has_images_path) and not is_excluded and is_long_enough
    
    async def assign_product_to_all_categories(self, db: AsyncSession, product_id: int, 
                                             default_category_id: int, category_matches: List[Dict]):
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–µ—Ä—Å–∏—è: –ù–∞–∑–Ω–∞—á–∞–µ—Ç –ø—Ä–æ–¥—É–∫—Ç –≤–æ –≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        """
        try:
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Å–≤—è–∑–∏ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
            await self.clear_product_categories(db, product_id)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—Å–Ω–æ–≤–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            await self.add_product_to_category(db, product_id, default_category_id, is_primary=True)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            for category_match in category_matches:
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ —Å–ª–æ–≤–∞—Ä—è
                category_id = category_match['id']
                category_name = category_match['name']
                
                if category_id != default_category_id:
                    await self.add_product_to_category(db, product_id, category_id, is_primary=False)
                    self.logger.info(f"–ü—Ä–æ–¥—É–∫—Ç {product_id} –¥–æ–±–∞–≤–ª–µ–Ω –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—é '{category_name}' (ID: {category_id})")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø—Ä–æ–¥—É–∫—Ç—É {product_id}: {e}", exc_info=True)
            raise

    def _prepare_product_text_for_analysis(self, product_in: ProductCreate) -> str:
        """
        –£–ü–†–û–©–ï–ù–û: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–¥—É–∫—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        (—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Ç–µ–ø–µ—Ä—å –≤ –æ–ø–∏—Å–∞–Ω–∏–∏)
        """
        text_parts = []
        
        # –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞ (—Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π —Ç–µ–∫—Å—Ç)
        if hasattr(product_in, 'name') and product_in.name:
            text_parts.append(product_in.name)
        
        # –û–ø–∏—Å–∞–Ω–∏–µ (—Ç–µ–ø–µ—Ä—å —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏)
        if hasattr(product_in, 'description') and product_in.description:
            text_parts.append(product_in.description)
        
        # –ú–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if hasattr(product_in, 'meta_title') and product_in.meta_title:
            text_parts.append(product_in.meta_title)
        
        if hasattr(product_in, 'meta_description') and product_in.meta_description:
            text_parts.append(product_in.meta_description)
        
        # –ê—Ä—Ç–∏–∫—É–ª (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if hasattr(product_in, 'article') and product_in.article:
            text_parts.append(product_in.article)
        
        result = " ".join(text_parts)
        self.logger.debug(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ ({len(result)} —Å–∏–º–≤–æ–ª–æ–≤): {result[:100]}...")
        return result